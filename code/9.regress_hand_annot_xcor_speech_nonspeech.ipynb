{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control repeat cross-correlation analysis (spectral envelope and HFB) after regressing out hand annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pympi\n",
    "from scipy.stats import ttest_ind\n",
    "from wilcoxon import wilcoxon\n",
    "from utils import zscore, cross_correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load elan annotations\n",
    "D = pympi.Elan.Eaf('../data/hand_presence_annotation_fragments.eaf')\n",
    "tiers = ['hands_speech', 'hands_nonspeech', 'speech', 'nonspeech']\n",
    "assert all([i in D.get_tier_names() for i in tiers])\n",
    "\n",
    "A = {}\n",
    "for itier in tiers:\n",
    "    temp = np.array(D.get_annotation_data_for_tier(itier)).astype(np.int32).T\n",
    "    A[itier] = {}\n",
    "    A[itier]['start'], A[itier]['end'], A[itier]['text'] = temp\n",
    "\n",
    "# at 1000 Hz\n",
    "for itier in tiers:\n",
    "    s = np.argsort(A[itier]['start'])\n",
    "    for k, v in A[itier].items():\n",
    "        A[itier][k] = v[s]\n",
    "\n",
    "down10 = lambda x: np.round(x/10.).astype(np.int32)\n",
    "speech = down10(np.stack([A['speech']['start'], A['speech']['end']]).T)\n",
    "nonspeech = down10(np.stack([A['nonspeech']['start'], A['nonspeech']['end']]).T)\n",
    "hand_speech = down10(np.stack([A['hands_speech']['start'], A['hands_speech']['end']]).T)\n",
    "hand_nonspeech = down10(np.stack([A['hands_nonspeech']['start'], A['hands_nonspeech']['end']]).T)\n",
    "hand_speech_vec = A['hands_speech']['text'].T\n",
    "hand_nonspeech_vec = A['hands_nonspeech']['text'].T\n",
    "\n",
    "for i, ispe in enumerate(speech):\n",
    "    if (ispe[1] - ispe[0]) > 400:\n",
    "        ispe[1] = ispe[0] + 400\n",
    "for i, inon in enumerate(nonspeech):\n",
    "    if (inon[1] - inon[0]) > 400:\n",
    "        inon[1] = inon[0] + 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 x 2: speech presence/absence and hand presence/absence\n",
    "def binarize1(x):\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "# 2 x 2: speech presence/absence and hand movement/hand absence\n",
    "def binarize2(x):\n",
    "    x[x==1] = 0\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "# 2 x 3: speech presence/absence and hand movement/presence/absence\n",
    "def split_three(x):\n",
    "    x[x>2] = 2\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct hand regressor \n",
    "def construct_hand_regressor(fragments, hand_time, hand_values):\n",
    "    hand_reg = []\n",
    "    for fragment in range(fragments.shape[0]):\n",
    "        ind = (hand_time[:, 0]>= fragments[fragment, 0]) & (hand_time[:, 1]<= fragments[fragment, 1]) |\\\n",
    "            (hand_time[:, 0]< fragments[fragment, 1]) & (hand_time[:, 1] >= fragments[fragment, 1]) |\\\n",
    "            (hand_time[:, 1]> fragments[fragment, 0]) & (hand_time[:, 0] <= fragments[fragment, 0])\n",
    "\n",
    "        #print(fragments[fragment])\n",
    "        #print(hand_time[ind])\n",
    "        #print(hand_values[ind])\n",
    "\n",
    "        st, en = fragments[fragment]\n",
    "        #print(hand_time[ind].shape[0])\n",
    "        if hand_time[ind].shape[0] == 1:\n",
    "            hand_reg.append(np.tile(hand_values[ind], [en-st]))\n",
    "        elif hand_time[ind].shape[0] > 1:\n",
    "            temp = np.zeros(400, dtype=np.int32)\n",
    "            for i in range(hand_time[ind].shape[0]):\n",
    "                st1, en1 = hand_time[ind][i] - st\n",
    "                temp[st1 if st1 >=0 else 0 : en1 if en1 <= 400 else 400] = hand_values[ind][i]\n",
    "            hand_reg.append(temp)\n",
    "        #print(hand_reg[-1])\n",
    "    return np.array(hand_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regress out hand presence from ecog\n",
    "def regress_z(x, z):\n",
    "    c = np.linalg.lstsq(np.c_[z, np.ones(z.shape[0])], x)[0]\n",
    "    r = x - np.c_[z, np.ones(z.shape[0])].dot(c)\n",
    "    return r.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = 's1'\n",
    "x    = np.load('../data/' + subj + '_HD_100Hz_hfb.npy')\n",
    "pm   = np.load('../results/ttest_ecog_speech_nonspeech_'+subj+'_pmask.npz')['pmask_bonf'] # pmask from the first ttest\n",
    "grid = np.load('../data/' + subj + '_HD_grid.npy')\n",
    "n    = x.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julia/Documents/Python/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16.42408618 11.80228885 -5.00481672 26.58881036 12.77547079 26.32934601\n",
      " 14.39202491 14.13282602  3.74210763 17.52181339 10.05418485  3.81229241\n",
      "  7.89557077 14.37351416  6.14536781  4.55402917  6.82191685  3.96497827]\n",
      "[16.34582962 11.72382423 -4.85197143 26.62437594 12.78006145 26.43590348\n",
      " 14.33138275 14.14851255  3.78837978 17.55815366 10.06085852  3.78531154\n",
      "  7.90169985 14.42951345  6.18705523  4.59146867  6.85102048  4.0257282 ]\n",
      "96.0 -0.3359940268259508 0.7368753708069717\n"
     ]
    }
   ],
   "source": [
    "# t-test HFB speech vs nonspeech\n",
    "hand_speech_vec = split_three(A['hands_speech']['text'].T.copy())\n",
    "hand_nonspeech_vec = split_three(A['hands_nonspeech']['text'].T.copy())\n",
    "hand_speech_reg = construct_hand_regressor(speech, hand_speech, hand_speech_vec)\n",
    "hand_non_reg = construct_hand_regressor(nonspeech, hand_nonspeech, hand_nonspeech_vec)\n",
    "\n",
    "# regress out hand from HFB\n",
    "d_spe, d_non = [], []\n",
    "for spe_frag, non_frag in zip(speech, nonspeech):\n",
    "        d_spe.append(x[range(spe_frag[0], spe_frag[1])])\n",
    "        d_non.append(x[range(non_frag[0], non_frag[1])])\n",
    "\n",
    "d_spe, d_non = map(np.array, [d_spe, d_non])\n",
    "\n",
    "d_all_c = np.concatenate([d_spe, d_non]).reshape((-1, n))\n",
    "hand_all_c = np.concatenate([hand_speech_reg, hand_non_reg]).flatten()\n",
    "\n",
    "d_all_rs = regress_z(d_all_c, hand_all_c)\n",
    "\n",
    "d_all_rs = d_all_rs.reshape((-1, 400, n))\n",
    "d_all_rs_m = np.mean(d_all_rs, 1)\n",
    "\n",
    "# t-test to compare mean HFB in speech and non-speech fragments after regressing hand\n",
    "ts_reg, ps_reg = np.zeros(d_all_rs_m.shape[-1]), np.zeros(d_all_rs_m.shape[-1])\n",
    "for i in range(d_all_rs_m.shape[-1]):\n",
    "    ts_reg[i], ps_reg[i] = ttest_ind(d_all_rs_m[:115, i], d_all_rs_m[115:, i])\n",
    "print(ts_reg[np.where(ps_reg<.05/n)[0]])\n",
    "\n",
    "# original T-test to compare mean HFB in speech and non-speech fragments\n",
    "d_spe, d_non = [], []\n",
    "for spe_frag, non_frag in zip(speech, nonspeech):\n",
    "        d_spe.append(np.mean(x[range(spe_frag[0], spe_frag[1])], 0))\n",
    "        d_non.append(np.mean(x[range(non_frag[0], non_frag[1])], 0))\n",
    "\n",
    "d_spe, d_non = map(np.array, [d_spe, d_non])\n",
    "\n",
    "ts, ps = np.zeros(x.shape[-1]), np.zeros(x.shape[-1])\n",
    "for i in range(x.shape[-1]):\n",
    "    ts[i], ps[i] = ttest_ind(d_spe[:, i], d_non[:, i])\n",
    "print(ts[np.where(ps<.05/n)[0]])\n",
    "\n",
    "# Wilcoxon for testing difference in t-statistics (speech vs nonspeech in HFB) with regressing hand vs not regressing hand\n",
    "wilx = wilcoxon(zscore(ts[pm])-zscore(ts_reg[pm]), alternative='two-sided', zero_method='zsplit')\n",
    "print(wilx.w_statistic, wilx.z_statistic, wilx.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julia/Documents/Python/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.0 -0.05923488777590923 0.9527650219907529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julia/Documents/project_minoes_motor/shared/code/wilcoxon.py:126: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "# t-test correlation to audio envelope in speech vs nonspeech \n",
    "\n",
    "a = np.load('../data/audio_envelope_100Hz.npy')\n",
    "hand_speech_vec = binarize1(A['hands_speech']['text'].T.copy())\n",
    "hand_nonspeech_vec = binarize1(A['hands_nonspeech']['text'].T.copy())\n",
    "hand_speech_reg = construct_hand_regressor(speech, hand_speech, hand_speech_vec)\n",
    "hand_non_reg = construct_hand_regressor(nonspeech, hand_nonspeech, hand_nonspeech_vec)\n",
    "\n",
    "# regress out hand from HFB\n",
    "d_spe, d_non = [], []\n",
    "for spe_frag, non_frag in zip(speech, nonspeech):\n",
    "        d_spe.append(x[range(spe_frag[0], spe_frag[1])])\n",
    "        d_non.append(x[range(non_frag[0], non_frag[1])])\n",
    "\n",
    "d_spe, d_non = map(np.array, [d_spe, d_non])\n",
    "\n",
    "d_all_c = np.concatenate([d_spe, d_non]).reshape((-1, n))\n",
    "hand_all_c = np.concatenate([hand_speech_reg, hand_non_reg]).flatten()\n",
    "\n",
    "d_all_rs = regress_z(d_all_c, hand_all_c)\n",
    "\n",
    "d_all_rs = d_all_rs.reshape((-1, 400, n))\n",
    "d_spe_rs = d_all_rs[:115]\n",
    "d_non_rs = d_all_rs[115:]\n",
    "\n",
    "# correlation to audio envelope: after regressing hand\n",
    "r_spe, r_non = [], []\n",
    "for ifrag, (spe_frag, non_frag) in enumerate(zip(speech, nonspeech)):\n",
    "    r_spe.append([])\n",
    "    r_non.append([])\n",
    "    for i in range(x.shape[-1]):\n",
    "        r_spe[-1].append(cross_correlate(d_spe_rs[ifrag, :, i], a[range(spe_frag[0], spe_frag[1])], type='spearman'))\n",
    "        r_non[-1].append(cross_correlate(d_non_rs[ifrag, :, i], a[range(non_frag[0], non_frag[1])], type='spearman'))\n",
    "\n",
    "r_spe, r_non = np.array(r_spe), np.array(r_non)\n",
    "\n",
    "# take max within [-100:500] ms per fragment\n",
    "r_spe_m_reg = np.max(r_spe[:,:,390:-349], 2)\n",
    "r_non_m_reg = np.max(r_non[:,:,390:-349], 2)\n",
    "\n",
    "# fisher transform\n",
    "r_spe_mf = np.arctanh(r_spe_m_reg)\n",
    "r_non_mf = np.arctanh(r_non_m_reg)\n",
    "\n",
    "# t-test on spe vs non after regressing hand\n",
    "ts_reg, ps_reg = [], []\n",
    "for i, j in zip(r_spe_mf.T, r_non_mf.T):\n",
    "    t, p = ttest_ind(i, j)\n",
    "    ts_reg.append(t)\n",
    "    ps_reg.append(p)\n",
    "ts_reg, ps_reg = np.array(ts_reg), np.array(ps_reg)\n",
    "\n",
    "# original correlation\n",
    "r_spe, r_non = [], []\n",
    "for spe_frag, non_frag in zip(speech, nonspeech):\n",
    "    r_spe.append([])\n",
    "    r_non.append([])\n",
    "    for i in range(x.shape[-1]):\n",
    "        r_spe[-1].append(cross_correlate(x[spe_frag[0]:spe_frag[1], i], a[spe_frag[0]:spe_frag[1]], type='spearman'))\n",
    "        r_non[-1].append(cross_correlate(x[non_frag[0]:non_frag[1], i], a[non_frag[0]:non_frag[1]], type='spearman'))\n",
    "\n",
    "r_spe, r_non = np.array(r_spe), np.array(r_non)\n",
    "\n",
    "r_spe_m = np.max(r_spe[:,:,390:-349], 2)\n",
    "r_non_m = np.max(r_non[:,:,390:-349], 2)\n",
    "\n",
    "# fisher transform\n",
    "r_spe_mf = np.arctanh(r_spe_m)\n",
    "r_non_mf = np.arctanh(r_non_m)\n",
    "\n",
    "# t-test on original correlations\n",
    "ts, ps = [], []\n",
    "for i, j in zip(r_spe_mf.T, r_non_mf.T):\n",
    "    t, p = ttest_ind(i, j)\n",
    "    ts.append(t)\n",
    "    ps.append(p)\n",
    "ts, ps = np.array(ts), np.array(ps)\n",
    "ts_masked = ts.copy()\n",
    "\n",
    "# select only significant electrodes from the original analysis\n",
    "ts_masked[np.setdiff1d(range(n), pm)] = 0\n",
    "thresh_01 = 1e-2/pm.shape[0]\n",
    "ts_masked[ps >= thresh_01] = 0\n",
    "ts_reg_masked = ts_reg.copy()\n",
    "ts_reg_masked[np.setdiff1d(range(n), pm)] = 0\n",
    "ts_reg_masked[ps >= thresh_01] = 0\n",
    "\n",
    "# Wilcoxon for testing difference in t-statistics (correlation to audio envelope in speech vs nonspeech) with regressing hand vs not regressing hand\n",
    "wilx = wilcoxon(zscore(ts_masked[ts_masked>0])-zscore(ts_reg_masked[ts_masked>0]), alternative='two-sided', zero_method='zsplit')\n",
    "print(wilx.w_statistic, wilx.z_statistic, wilx.pvalue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
